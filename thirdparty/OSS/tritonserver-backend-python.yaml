#nolint:git-checkout-must-use-github-updates,valid-pipeline-git-checkout-tag
package:
  name: tritonserver-backend-python
  version: 24.08
  epoch: 1
  description: NVIDIA Triton Inference Server Python Backend
  copyright:
    - license: BSD-3-Clause
  target-architecture:
    - x86_64
  resources:
    cpu: 64
    memory: 192Gi
  dependencies:
    runtime:
      - libarchive
      - libstdc++-12
      - nvidia-cuda-cudart-${{vars.cuda-version}}
      - nvidia-cuda-cupti-${{vars.cuda-version}}
      - rapidjson
      - python-${{vars.py-version}}-base
      - py${{vars.py-version}}-numpy
      - zlib
  options:
    no-depends: true

vars:
  cuda-version: 12.5
  py-version: 3.10
  tensorrt-version: 10.3.0.26
  triton-repo-tag: r24.08

var-transforms:
  - from: ${{vars.cuda-version}}
    match: (\d+)\.\d+
    replace: $1
    to: cuda-major-version

environment:
  contents:
    packages:
      - build-base
      - busybox
      - ca-certificates-bundle
      - cmake
      - cuda-toolkit-${{vars.cuda-version}}
      - file
      - gcc-12
      - gcc-12-default
      - libarchive-dev
      - nvidia-cuda-cudart-${{vars.cuda-version}}
      - nvidia-cuda-cudart-${{vars.cuda-version}}-dev
      - nvidia-cuda-cupti-${{vars.cuda-version}}
      - nvidia-cuda-cupti-${{vars.cuda-version}}-dev
      - nvidia-cuda-nvcc-${{vars.cuda-version}}-dev
      - py${{vars.py-version}}-build-base-dev
      - rapidjson-dev
      - zlib-dev
  environment:
    LD_LIBRARY_PATH: "/usr/local/cuda-${{vars.cuda-version}}/lib64:/usr/local/cuda-${{vars.cuda-version}}/lib64/stubs"

pipeline:
  - uses: git-checkout
    with:
      # c848884d24e71b20a1636e7e63435ca8daba097b is the commit for r24.04
      # Becareful about changing the commit because you need to keep it in sync with the tags for the other repositories it pulls in.
      # N.B. r24.04 is a branch; there doesn't appear to be specific tags. So I think potentially they could push a change to the
      # branch and it would end up changing the commit we build but hopefully that's caught by expected commit
      expected-commit: bbb523d3189265b7c4e1c42a0fbe1a48869c1623
      repository: https://github.com/triton-inference-server/python_backend.git
      branch: r${{package.version}}
      destination: backend
      recurse-submodules: true

  - runs: |
      # This is a bit of hack to fix the warnings
      # See: https://github.com/chainguard-dev/extra-packages/pull/407#issuecomment-2223704174
      sed -e 's/-Werror//g' -i /home/build/backend/CMakeLists.txt

  # TRT_VERSION is set based on the instructions in the repository
  # https://github.com/triton-inference-server/tensorrtllm_backend?tab=readme-ov-file#option-1-build-via-the-buildpy-script-in-server-repo
  #
  - runs: |
      export PATH="$PATH:/usr/local/cuda-${{vars.cuda-version}}/bin"
      # CUDA detection needs path set to find nvcc so we  call cmake directly

      mkdir output
      cd output
      cmake \
        "-DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-${{vars.cuda-version}}" \
        "-DTRT_VERSION=${{vars.tensorrt-version}}" \
        "-DCMAKE_TOOLCHAIN_FILE=${CMAKE_TOOLCHAIN_FILE}" \
        "-DVCPKG_TARGET_TRIPLET=${VCPKG_TARGET_TRIPLET}" \
        "-DCMAKE_BUILD_TYPE=Release" \
        "-DCMAKE_INSTALL_PREFIX:PATH=/tmp/tritonbuild/python/install" \
        "-DTRITON_REPO_ORGANIZATION:STRING=https://github.com/triton-inference-server" \
        "-DTRITON_COMMON_REPO_TAG:STRING=${{vars.triton-repo-tag}}" \
        "-DTRITON_CORE_REPO_TAG:STRING=${{vars.triton-repo-tag}}" \
        "-DTRITON_BACKEND_REPO_TAG:STRING=${{vars.triton-repo-tag}}" \
        "-DTRITON_ENABLE_GPU:BOOL=ON" \
        "-DTRITON_ENABLE_MALI_GPU:BOOL=OFF" \
        "-DTRITON_ENABLE_STATS:BOOL=ON" \
        "-DTRITON_ENABLE_METRICS:BOOL=ON" \
        "-DTRITON_ENABLE_MEMORY_TRACKER:BOOL=ON" \
        "-DCMAKE_CXX_FLAGS=\"-Wno-error=deprecated-declarations\""  \
        /home/build/backend

  - runs: |
      # N.B. I'm not sure how we would convert this to use the cmake/build pipeline
      # https://github.com/chainguard-dev/melange/blob/main/pkg/build/pipelines/cmake/build.yaml
      # Because it doesn't look like that lets us specify additional options.
      cmake --build /home/build/output --config Release -j20  -t install

      # INSTALLDIR is the directory where the built artifacts are placed after running cmake install
      export INSTALLDIR=/tmp/tritonbuild/python/install

      # Dest dir is the directory in final output where we should put the artifacts
      # See https://github.com/triton-inference-server/server/issues/7410#issuecomment-2218856792
      # If we don't put the python backend in the default location /opt/tritonserver/backends/python
      # we have problems later on when trying to specify the location of the backend.
      # So just use the default location.
      export DESTDIR="${{targets.contextdir}}/opt/tritonserver"
      mkdir -p ${DESTDIR}/backends
      rm -fr ${DESTDIR}/backends/python
      cp -r ${INSTALLDIR}/backends/python ${DESTDIR}/backends

test:
  pipeline:
    - name: python dependency smoke test
      runs: |
        # Make sure the imports in this script don't fail
        python${{vars.py-version}} /opt/tritonserver/backends/python/triton_python_backend_utils.py

update:
  enabled: false
  exclude-reason: "upstream not using tags or releases"
